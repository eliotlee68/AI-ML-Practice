def find_number_of_epochs(X, y, lr, delta_loss):
    '''
    Do gradient descent until convergence and return number of epochs
    required.
    Parameters
    ----------
    X (np.ndarray) : (m, n) numpy matrix representing feature matrix
    y (np.ndarray) : (m, 1) numpy matrix representing target values
    lr (float) : Learning rate
    delta_loss (float) : Termination criterion
    
    Returns
    -------
        bias (float):
            The bias constant
        weights (np.ndarray):
            A (n, 1) numpy matrix that specifies the weight constants.
        num_of_epochs (int):
            Number of epochs to reach convergence.
        current_loss (float):
            The loss value obtained after convergence.
    '''
    # Do not change
    bias = 0
    weights = np.full((X.shape[1], 1), 0).astype(float)
    num_of_epochs = 0
    previous_loss = 1e14
    current_loss = -1e14
    m = y.shape[0]
    y_pred = np.matmul(X, weights) + bias
    while abs(previous_loss - current_loss) >= delta_loss:
        # TODO: add your solution here and remove `raise NotImplementedError`
        previous_loss = current_loss
        error = y_pred - y
        biasDerive = (1/m) * np.sum(error)
        weightsDerive = (1/m) * np.matmul(np.transpose(X), error)
        bias -= (lr * biasDerive)
        weights -= (lr * weightsDerive)
        y_pred = np.matmul(X, weights) + bias
        current_loss = mean_squared_error(y_pred, y)
        num_of_epochs += 1
    return bias, weights, num_of_epochs, current_loss
